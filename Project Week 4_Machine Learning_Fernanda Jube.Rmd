---
title: "Machine Learning_Fernanda Jube"
author: "FJube"
date: "10/05/2020"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction


The aim of this project is to take the data regarding accelerometers on the belt, forearm, arm, and dumbell taken from quantifying self movement devices of 6 participants and predict the manner in which they did the exercise.
The first step is to train the data taking the training data using different algorithims. After that a predition will be realized and the model that has the highest accuracy will be selected.


## Loading the data


```{r accelerometers load1, echo=TRUE}
library(caret)
training<-read.csv('pml-training.csv')
testing<-read.csv('pml-testing.csv')
head(training)
```

## Pre-processing the data
As we could observe in the training data frame, there are some strings as "#DIV/0!" that must be eliminated. So the reloaded data is done as follows:

```{r accelerometers load2, echo=TRUE}
training<-read.csv('pml-training.csv' , na.strings=c("#DIV/0!","NA"))
testing<-read.csv('pml-testing.csv', na.strings=c("#DIV/0!","NA"))
dim(training)
dim(testing)
```
As the analysis will be made regarding accelerometers on the belt, forearm, arm, and dumbell, the data frame will contain only the variables from "roll_bel" on.
Besides that the columns which are entirely fullfilled with 'NA' values will be eliminated. Another tool to 

```{r accelerometers null, echo=TRUE}
training[1:7]<-NULL
testing[1:7]<-NULL
training<-training[,colSums(is.na(training)) == 0]
testing <-testing[,colSums(is.na(testing)) == 0]
dim(training)
dim(testing)

```

## Parting data

```{r parting, echo=TRUE }
set.seed(3422)
datapart<-createDataPartition(training$classe,p=3/4)[[1]]
tr1 = training[datapart, ]
test1 = training[-datapart, ]
```


## Training data

The algorithims choosen to train the data are random forest and decision tree which are the most indicated to predict categorical variables.

### Random Forest

```{r rf, echo=TRUE }
library(randomForest)
set.seed(34511)
mode_rf<-randomForest(classe~.,data=tr1)
pred_rf<-predict(mode_rf,test1)
confusionMatrix(pred_rf, test1$classe)
```

### Decision Tree
```{r dt, echo=TRUE }
library(rpart) 
set.seed(34511)
mode_dt<-rpart(classe ~ ., data=tr1, method="class")
pred_dt<-predict(mode_dt, test1, type = "class")
confusionMatrix(pred_dt, test1$classe)
```

```{r dt2, echo=TRUE }
mode_dt$finalModel
library(rattle)
fancyRpartPlot(mode_dt)
```
As we can check from the decision tree chart, the species are majority A class. 

### Conclusion

The accuracy of each one of the models were:
Random Forest_Accuracy:0.9951 
Decision Tree_Accuracy:0.7482

That been concluded, the random forest is the model more adequated  to predict with this data.

### Quiz

```{r quiz, echo=TRUE }
quiz<-predict(mode_rf,testing,type="class")
quiz
```

### Bibliographic References
VELLOSO, E.; BULLING, A.; GELLERSEN, H.; UGULINO, W.; FUKS, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human â€™13) . Stuttgart, Germany: ACM SIGCHI, 2013.

